{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">Gradient Boosting and XGBoost</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl (18.3MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 360, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 442, in read\n",
      "    data = self._fp.read(amt)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\http\\client.py\", line 447, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\http\\client.py\", line 491, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 1052, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 911, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 178, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 352, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 131, in resolve\n",
      "    self._resolve_one(requirement_set, req)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 294, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\resolve.py\", line 242, in _get_abstract_dist_for\n",
      "    self.require_hashes\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 347, in prepare_linked_requirement\n",
      "    progress_bar=self.progress_bar\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 886, in unpack_url\n",
      "    progress_bar=progress_bar\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 746, in unpack_http_url\n",
      "    progress_bar)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 954, in _download_http_url\n",
      "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 683, in _download_url\n",
      "    hashes.check_against_chunks(downloaded_chunks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\utils\\hashes.py\", line 62, in check_against_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 651, in written_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\utils\\ui.py\", line 156, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\download.py\", line 640, in resp_read\n",
      "    decode_content=False):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 494, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 459, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 365, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/white-wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 1\n",
    "***\n",
    "### Instructions\n",
    "* Split the white-wine dataset into train and test set with `test_size = 0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X , y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.3,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 2\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "* Initialise a decision tree model(Weak Classifier) with DecisionTreeClassifier() having max_depth=1 & random_state=0 and save it to a variable called `dt_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `dt_score`\n",
    "\n",
    "* Initialise a AdaBoost model with AdaBoostClassifier() having base_estimator=dt_clf & random_state=0 and save it to a variable called `ada_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `ada_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak Learner Score:  0.42857142857142855\n",
      "Adaboost Score:  0.4326530612244898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Fitting of Weak Classifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=1 , random_state=0)\n",
    "dt_clf.fit(x_train,y_train)\n",
    "dt_score = dt_clf.score(x_test,y_test)\n",
    "print(\"Weak Learner Score: \",dt_score)\n",
    "\n",
    "# Fitting of weak classifier with Adaboost\n",
    "ada_clf = AdaBoostClassifier(base_estimator=dt_clf , random_state=0)\n",
    "ada_clf.fit(x_train,y_train)\n",
    "ada_score = ada_clf.score(x_test,y_test)\n",
    "print(\"Adaboost Score: \",ada_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 3\n",
    "***\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Initialise a Gradient Boost model with GradientBoostingClassifier() having random_state=0 and save it to a variable called `gb_clf`.\n",
    "\n",
    "* Fit the model on the training data `x_train` and `y_train` using the `fit()` method.\n",
    "\n",
    "* Find out the accuracy score between `x_test` and `y_test` using the `score()` method and save it in a variable called `gb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Score:  0.5727891156462585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state =0)\n",
    "gb_clf.fit(x_train,y_train)\n",
    "gb_score = gb_clf.score(x_test,y_test)\n",
    "print(\"Gradient Boost Score: \",gb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 4\n",
    "***\n",
    "### Instructions\n",
    "* For this challenge, you will have to install `xgboost` library. Import `xgboost` and instantiate `XGBClassifier()` and fit it on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a7742f297225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(random_state=0)\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 5\n",
    "***\n",
    "### Instructions\n",
    "* Predict the model on the test set and check the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5619047619047619"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 6\n",
    "***\n",
    "### Instructions\n",
    "* Now let's do some hyperparameter tuning by defining the parameters `'colsample_bytree': np.linspace(0.5, 0.9, 5)`,`'n_estimators':[5, 10]`,`'max_depth': [10, 15, 20, 25]` and then fit them into a GridSearchCV model with `scoring = 'neg_mean_squared_error'`and cross_ validation parameter `cv = 5`<br/><br/>Feel free to experiment on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gbm_param_grid = {\n",
    "     'colsample_bytree': np.linspace(0.5, 0.9, 5),\n",
    "     'n_estimators':[5, 10],\n",
    "     'max_depth': [10, 15, 20, 25]\n",
    "}\n",
    "\n",
    "grid_mse = GridSearchCV(estimator = model, param_grid = gbm_param_grid, scoring = 'accuracy', cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 7\n",
    "***\n",
    "### Instructions\n",
    "* Fit the GridSearchCV model on the train dataset and get the best parametres and the Highest Accuracy found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.6, 'max_depth': 25, 'n_estimators': 10}\n",
      "Highest Accuracy found:  0.6490665110851809\n"
     ]
    }
   ],
   "source": [
    "grid_mse.fit(x_train, y_train)\n",
    "print(\"Best parameters found: \",grid_mse.best_params_)\n",
    "print(\"Highest Accuracy found: \", grid_mse.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/ppt-icons.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "### Mini Challenge - 8\n",
    "***\n",
    "### Instructions\n",
    "* Make a prediction on the test dataset and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482993197278911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grid_mse.predict(x_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/icon/quiz.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "# Gradient Boosting Machines\n",
    "***\n",
    "```python\n",
    "Q1. Which of the following is true about “max_depth” hyperparameter in Gradient Boosting?\n",
    "\n",
    "Lower is better parameter in case of same validation accuracy\n",
    "Higher is better parameter in case of same validation accuracy\n",
    "Increase the value of max_depth may overfit the data\n",
    "Increase the value of max_depth may underfit the data\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "Solution: A\n",
    "\n",
    "Increase the depth from the certain value of depth may overfit the data and for 2 depth values validation accuracies are same we always prefer the small depth in final model building.\n",
    "```\n",
    "```python\n",
    "Q2. Which of the following algorithm doesn’t uses learning Rate as of one of its hyperparameter?\n",
    "\n",
    "Gradient Boosting\n",
    "Extra Trees\n",
    "AdaBoost\n",
    "Random Forest\n",
    "A) 1 and 3\n",
    "B) 1 and 4\n",
    "C) 2 and 3\n",
    "D) 2 and 4\n",
    "\n",
    "Solution: D\n",
    "\n",
    "Random Forest and Extra Trees don’t have learning rate as a hyperparameter.\n",
    "```\n",
    "```python\n",
    "Q3. Which of the following is true about the Gradient Boosting trees?\n",
    "\n",
    "In each stage, introduce a new regression tree to compensate the shortcomings of existing model\n",
    "We can use gradient decent method for minimize the loss function\n",
    "A) 1\n",
    "B) 2\n",
    "C) 1 and 2\n",
    "D) None of these\n",
    "\n",
    "Solution: C\n",
    "\n",
    "Both are true and self explanatory\n",
    "```\n",
    "```python\n",
    "Q4. In greadient boosting it is important use learning rate to get optimum output. Which of the following is true abut choosing the learning rate?\n",
    "\n",
    "A) Learning rate should be as high as possible\n",
    "B) Learning Rate should be as low as possible\n",
    "C) Learning Rate should be low but it should not be very low\n",
    "D) Learning rate should be high but it should not be very high\n",
    "\n",
    "Solution: C\n",
    "\n",
    "Learning rate should be low but it should not be very low otherwise algorithm will take so long to finish the training because you need to increase the number trees.\n",
    "```\n",
    "```python\n",
    "Q5. [True or False] Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.\n",
    "\n",
    "A) TRUE\n",
    "B) FALSE\n",
    "\n",
    "Solution: A\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You\n",
    "***\n",
    "### Next Session: Challenges in ML\n",
    "For more queries - Reach out to academics@greyatom.com "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
